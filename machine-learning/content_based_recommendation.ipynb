{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrxvhixNEpL",
        "outputId": "b910f28a-36c6-4875-d285-1f2d6f896784"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7itcmOFn5mG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbZ5XvoPKCyM"
      },
      "source": [
        "## Collect Data from TMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-Ccyy4FyCKu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "from google.colab import userdata\n",
        "tmdb_token = userdata.get('tmdb_auth')\n",
        "\n",
        "# print(tmdb_token)\n",
        "\n",
        "url = \"https://api.themoviedb.org/3/movie/popular?language=en-US&page=1\"\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer \" + tmdb_token\n",
        "}\n",
        "response = requests.get(url, headers=headers)\n",
        "data = response.json() #convert response to dictionary\n",
        "# print(data)\n",
        "# print(json.dumps(data, indent=4)) #convert dictionary to JSON-formatted string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "30gbe8XMKHom",
        "outputId": "e0b18ebd-6f1c-4d35-abe5-d96c485e9ad3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# construct movies dataframe\n",
        "movies_list = data['results'] #extracts list of movies\n",
        "movies_df = pd.DataFrame(movies_list)\n",
        "\n",
        "# filter relevant columns\n",
        "relevant_columns = ['id', 'title', 'overview', 'genre_ids', 'vote_average', 'popularity', 'release_date']\n",
        "movies_df = movies_df[relevant_columns]\n",
        "\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmSMUP_uL_iR"
      },
      "outputs": [],
      "source": [
        "# movies_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jEsL8yf84jB",
        "outputId": "b16e5c94-3adc-409b-ac8e-deb4e1a10611"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary mapping movie ID to index\n",
        "id_to_index = pd.Series(movies_df.index, index=movies_df['id']).to_dict()\n",
        "print(id_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S9NzHjWndtL"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNhodjbYMnz6"
      },
      "source": [
        "### Text Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMJ4CM1qMpeY"
      },
      "outputs": [],
      "source": [
        "sw = stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42QYBGBihUvc"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) #  remove unwanted characters\n",
        "    text = re.sub(r\"http\\S+\", \"\",text) # remove URLs\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
        "    for p in punctuations:\n",
        "        text = text.replace(p,'') #remove punctuation marks\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw] #tokenize / remove stopwords\n",
        "    text = [lemmatizer.lemmatize(word) for word in text] #convert word to its base form\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_-sORYb3MtIf",
        "outputId": "622b264c-17a6-423e-ffcc-09a8195c758d"
      },
      "outputs": [],
      "source": [
        "movies_df['overview'] = movies_df['overview'].apply(lambda x: clean(x))\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF_Q0IY4TvEq"
      },
      "source": [
        "### MinMaxScaler\n",
        "For the numerical columns like average votes, I used the min max scaler to scale values into the specified range of 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "upWpkA_pT5-k",
        "outputId": "70475892-dd00-413c-bcf6-b286dc893924"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def preprocess_minmax(data):\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  return scaler.fit_transform(data)\n",
        "\n",
        "movies_df['normalized_vote'] = preprocess_minmax(movies_df[['vote_average']])\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egsf6jvNvesi"
      },
      "source": [
        "### One-hot encoding\n",
        "\n",
        "For the categorical column like genre, I used one hot encoding to convert the variables into numerical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "Zeh_Z5oWvhJT",
        "outputId": "40ba18a8-0935-494d-c2db-3afa5019dd51"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer #useful for transforming categorical data like genre\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# transform genre IDs into a binary matrix\n",
        "one_hot_genres = mlb.fit_transform(movies_df['genre_ids'])\n",
        "\n",
        "# create a DataFrame from the encoded genres\n",
        "genres_df = pd.DataFrame(one_hot_genres, columns=mlb.classes_)\n",
        "\n",
        "# Concatenate the new genres DataFrame with the original movies DataFrame column-wise\n",
        "movies_df = pd.concat([movies_df, genres_df], axis=1)\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRhFFQV0vhWU"
      },
      "outputs": [],
      "source": [
        "# movies_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ3HgA0iOslz"
      },
      "source": [
        "### TF-IDF for feature extraction\n",
        "\n",
        "Converts text data like overview into numerical vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh8pohnkOrgz"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# Applying TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "movies_df['overview'] = movies_df['overview'].fillna('') # replace NaN with an empty string\n",
        "tfidf_matrix = tfidf.fit_transform(movies_df['overview']) # construct the TF-IDF matrix\n",
        "# print(tfidf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIYzpnTb0R6C"
      },
      "source": [
        "## Recommendation function to test combined features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Ko4O770TwQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# combine one-hot encoded genre with tf-idf matrix from overview feature, and normalized votes\n",
        "combined_features = np.hstack((tfidf_matrix.toarray(), one_hot_genres, movies_df[['normalized_vote']].to_numpy()))\n",
        "\n",
        "# Pre calculate Cosine Similarity for convenience\n",
        "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
        "\n",
        "# print(combined_features)\n",
        "# print(cosine_sim)\n",
        "\n",
        "# get recommendations based on cosine similarity\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # Check if the movie title exists in the DataFrame\n",
        "    if title in movies_df['title'].values:\n",
        "      # Get the index of the movie that matches the title\n",
        "      idx = movies_df.index[movies_df['title'] == title].tolist()[0]\n",
        "      # Get the pairwise similarity scores of all movies with that movie\n",
        "      sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "      # Sort the movies based on the similarity scores\n",
        "      sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "      sim_scores = sim_scores[1:11]  # Get top 10 similar movies\n",
        "      movie_indices = [i[0] for i in sim_scores] # Get the movie indices\n",
        "      return movies_df['title'].iloc[movie_indices]\n",
        "\n",
        "    else:\n",
        "      return \"Movie title not found in the dataset.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLuTuJle1Tq5",
        "outputId": "4be4ddc6-15c1-4cb1-91c8-c3d475f7d439"
      },
      "outputs": [],
      "source": [
        "# Test the recommendation system with a movie title\n",
        "recommendations = get_recommendations(\"Aquaman and the Lost Kingdom\")\n",
        "print(recommendations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
